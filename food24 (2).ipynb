{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWR1FrjzOSpC",
        "outputId": "a77ad4cb-c1d7-4a36-a899-fcf5ab5c4176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow pandas Pillow gradio numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "kfooddb = pd.read_csv('food.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "iXJqsdgcOWSy"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존의 필요한 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n"
      ],
      "metadata": {
        "id": "O0zTxDKyOc8h"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩 및 제너레이터 설정 (기존과 동일)\n",
        "data_dir = '/content/foodImage'\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],        # 밝기 범위 설정\n",
        "    channel_shift_range=50,             # 채널(색상) 변형 설정\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "pZqUt08VOlz-"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmCniYeKPh8Y",
        "outputId": "3c44ee01-0e1e-4ddc-929a-fbbc9476cc91"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2102 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdpzFYKzPj1u",
        "outputId": "41704eea-7636-4c84-cc60-e454320a2f13"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 520 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---\n",
        "# 3. 라벨 불일치 수정\n",
        "# ImageDataGenerator가 찾은 클래스 이름을 직접 사용합니다.\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"모델이 인식한 음식 라벨:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q_YBSfsVeqC",
        "outputId": "ca38c638-d5c0-46a5-fbdd-cbab4ab1a699"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델이 인식한 음식 라벨: ['.ipynb_checkpoints', '고사리나물', '곱창전골', '김치전', '깍두기', '달걀국', '달걀말이', '돼지갈비', '양념치킨', '전복죽', '호박전', '훈제오리']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. 훈련 가능한 레이어 수 조정 (핵심 변경 부분)\n",
        "# MobileNetV2 기반 모델 구축\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n"
      ],
      "metadata": {
        "id": "uEV1RylzBvaQ"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-45:]:\n",
        "    layer.trainable = True\n"
      ],
      "metadata": {
        "id": "szGQ0tKVPn-2"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 분류 레이어 추가 (기존과 동일)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "NSbMwlQsB11b"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "    \"balanced\",\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "gK2fF3V7prKz"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# 2. EarlyStopping 콜백 설정 (핵심 변경 부분)\n",
        "callbacks = [\n",
        "    # patience를 3으로 줄여 모델이 빠르게 과적합되기 전에 훈련을 중단\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    # ReduceLROnPlateau 설정은 유지\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "]\n"
      ],
      "metadata": {
        "id": "Z6wYQyD5cPxY"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"모델이 인식한 음식 라벨:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NPhL9c2qqCT",
        "outputId": "d98809af-f507-4767-ece9-fe4d94ce338b"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델이 인식한 음식 라벨: ['.ipynb_checkpoints', '고사리나물', '곱창전골', '김치전', '깍두기', '달걀국', '달걀말이', '돼지갈비', '양념치킨', '전복죽', '호박전', '훈제오리']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일 및 학습\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "djnHW_tpPqop"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit() 함수에서 epochs 값을 변경하세요.\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9X-Dp9rPtO7",
        "outputId": "b8a9fbe9-45c8-44dd-e4fe-ee83f93778af"
      },
      "execution_count": 212,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.2591 - loss: 2.3132 - val_accuracy: 0.5115 - val_loss: 1.4994 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.6853 - loss: 0.9442 - val_accuracy: 0.5885 - val_loss: 1.4159 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - accuracy: 0.8075 - loss: 0.6154 - val_accuracy: 0.6135 - val_loss: 1.3792 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.8315 - loss: 0.5137 - val_accuracy: 0.6096 - val_loss: 1.4036 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.8703 - loss: 0.4098 - val_accuracy: 0.6269 - val_loss: 1.2964 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.8692 - loss: 0.3939 - val_accuracy: 0.6808 - val_loss: 1.1575 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.9086 - loss: 0.2893 - val_accuracy: 0.6615 - val_loss: 1.1686 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9131 - loss: 0.2418 - val_accuracy: 0.6538 - val_loss: 1.2843 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.9187 - loss: 0.2365 - val_accuracy: 0.7135 - val_loss: 0.9947 - learning_rate: 5.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.9460 - loss: 0.1831 - val_accuracy: 0.7327 - val_loss: 0.9322 - learning_rate: 5.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9399 - loss: 0.1815 - val_accuracy: 0.7442 - val_loss: 0.8590 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.9453 - loss: 0.1545 - val_accuracy: 0.7712 - val_loss: 0.7954 - learning_rate: 5.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9569 - loss: 0.1374 - val_accuracy: 0.7558 - val_loss: 0.8086 - learning_rate: 5.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9581 - loss: 0.1363 - val_accuracy: 0.7731 - val_loss: 0.7369 - learning_rate: 5.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9489 - loss: 0.1374 - val_accuracy: 0.7885 - val_loss: 0.7210 - learning_rate: 5.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9646 - loss: 0.1233 - val_accuracy: 0.7962 - val_loss: 0.7518 - learning_rate: 5.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.9697 - loss: 0.1064 - val_accuracy: 0.8154 - val_loss: 0.6098 - learning_rate: 5.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.9657 - loss: 0.1045 - val_accuracy: 0.8038 - val_loss: 0.6049 - learning_rate: 5.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.9598 - loss: 0.1243 - val_accuracy: 0.8077 - val_loss: 0.6214 - learning_rate: 5.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9711 - loss: 0.0874 - val_accuracy: 0.7981 - val_loss: 0.7533 - learning_rate: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# 3. 라벨 불일치 수정\n",
        "# ImageDataGenerator가 찾은 클래스 이름을 직접 사용\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"모델이 인식한 음식 라벨:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBrTdUTl-Y4U",
        "outputId": "cee47297-ee41-4eb4-b920-7937b9312d6e"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델이 인식한 음식 라벨: ['.ipynb_checkpoints', '고사리나물', '곱창전골', '김치전', '깍두기', '달걀국', '달걀말이', '돼지갈비', '양념치킨', '전복죽', '호박전', '훈제오리']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history 객체에서 정확도와 손실 값 확인\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "print(\"Training Accuracy:\", train_accuracy[-1])\n",
        "print(\"Validation Accuracy:\", val_accuracy[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da5QPwv6DOe-",
        "outputId": "cf088fd0-cb30-4bb0-9dd5-59170a56df68"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9690770506858826\n",
            "Validation Accuracy: 0.7980769276618958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('foodim9.keras')"
      ],
      "metadata": {
        "id": "6CVZbmPhANKs"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 영양 DB 로드 (기존과 동일)\n",
        "nutrition_db = pd.read_csv('/content/food.csv', encoding='UTF-8')\n",
        "model = tf.keras.models.load_model(\"foodim6.keras\")"
      ],
      "metadata": {
        "id": "FUR3Ehuy-c-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio 함수 수정\n",
        "def predict_and_analyze_nutrition(img_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    predicted_food_name = class_names[predicted_class_index]\n",
        "\n",
        "    nutrition_info = nutrition_db[nutrition_db['음 식 명'] == predicted_food_name]\n",
        "    if not nutrition_info.empty:\n",
        "        info = nutrition_info.iloc[0]\n",
        "        result_text = (\n",
        "            f\"**분석 결과: {info['음 식 명']}**\\n\"\n",
        "            f\"--- (100g 기준 영양 정보) ---\\n\"\n",
        "            f\"칼로리: {info['에너지(kcal)']} kcal\\n\"\n",
        "            f\"단백질: {info['단백질(g)']} g\\n\"\n",
        "            f\"지방: {info['지방(g)']} g\\n\"\n",
        "            f\"탄수화물: {info['탄수화물(g)']} g\\n\"\n",
        "        )\n",
        "        return result_text\n",
        "    else:\n",
        "        return f\"'{predicted_food_name}'에 대한 영양 정보를 찾을 수 없습니다.\""
      ],
      "metadata": {
        "id": "dws9Ox_N-gwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nutrition_db.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0iNovtZGFkh",
        "outputId": "42ba6d70-178e-4e67-d56a-13f87cbe7277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['음 식 명', '중량(g)', '에너지(kcal)', '탄수화물(g)', '당류(g)', '지방(g)', '단백질(g)',\n",
            "       '칼슘(mg)', '인(mg)', '나트륨(mg)', '칼륨(mg)', '마그네슘(mg)', '철(mg)', '아연(mg)',\n",
            "       '콜레스테롤(mg)', '트랜스지방(g)'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('foodim4.keras')"
      ],
      "metadata": {
        "id": "jB9A6NTNQIl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"foodim7.keras\")"
      ],
      "metadata": {
        "id": "CDdJcyMQQL-C"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2nbxxbuUDGS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# history 객체에서 정확도와 손실 값 확인\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "XtKAeBfYQqWj"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Accuracy:\", train_accuracy[-1])\n",
        "print(\"Validation Accuracy:\", val_accuracy[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hAAOoDfQsbX",
        "outputId": "f781bddc-acc4-4ab3-f029-9ed240391777"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9158512949943542\n",
            "Validation Accuracy: 0.6480000019073486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "trained_model = tf.keras.models.load_model('foodim7.keras')"
      ],
      "metadata": {
        "id": "kLXeIT9UQw_0"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 예측 수행\n",
        "results = trained_model.predict(img_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M5TY_JOUAgZ",
        "outputId": "a8b9c61f-351b-4189-83b7-00334022d714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x787c1d64df80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"food_labels 길이:\", len(food_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcPaUCjtUEkT",
        "outputId": "fbb4161c-c56e-4d7b-c936-b587ce53221a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "food_labels 길이: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PRhCdDbUHgE",
        "outputId": "095304d1-824f-4d6e-d188-00184902dbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/foodImage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the predict function should work correctly.\n",
        "results = trained_model.predict(img_array)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ZYRFHfUOe8",
        "outputId": "a1cda42b-a510-48f4-aa2a-bd231bb1fb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "[[2.2989003e-07 1.6631458e-09 7.6916912e-08 1.9559285e-11 3.2113963e-03\n",
            "  9.9678826e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xW825X8_UscY"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 학습된 모델과 영양 DB 다시 로드\n",
        "loaded_model = load_model('/content/foodim9.keras')\n",
        "nutrition_db = pd.read_csv('/content/food.csv', encoding='UTF-8')"
      ],
      "metadata": {
        "id": "BsKix2oTUuxm"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 클래스 인덱스-이름 매핑\n",
        "class_indices = train_generator.class_indices\n",
        "class_names = {v: k for k, v in class_indices.items()}"
      ],
      "metadata": {
        "id": "IZ7sEhR8U300"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_analyze_nutrition(img_path):\n",
        "    # 이미지 전처리\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # 음식 예측\n",
        "    predictions = loaded_model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    predicted_food_name = class_names[predicted_class_index]\n",
        "\n",
        "    # 영양 정보 찾기\n",
        "    nutrition_info = nutrition_db[nutrition_db['음 식 명'] == predicted_food_name]\n",
        "\n",
        "    if not nutrition_info.empty:\n",
        "        info = nutrition_info.iloc[0]\n",
        "        result_text = (\n",
        "            f\"**분석 결과: {info['음 식 명']}**\\n\"\n",
        "            f\"--- (100g 기준 영양 정보) ---\\n\"\n",
        "            f\"칼로리: {info['에너지(kcal)']} kcal\\n\"\n",
        "            f\"단백질: {info['단백질(g)']} g\\n\"\n",
        "            f\"지방: {info['지방(g)']} g\\n\"\n",
        "            f\"탄수화물: {info['탄수화물(g)']} g\\n\"\n",
        "        )\n",
        "        return result_text\n",
        "    else:\n",
        "        return f\"'{predicted_food_name}'에 대한 영양 정보를 찾을 수 없습니다.\""
      ],
      "metadata": {
        "id": "0hOVLudMU63U"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Gradio 인터페이스로 사용자에게 보여주기\n",
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_and_analyze_nutrition,\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"음식 이미지 업로드\"),\n",
        "    outputs=gr.Textbox(label=\"영양 분석 결과\"),\n",
        "    title=\"음식 영양 분석기 🥗\",\n",
        "    description=\"음식 이미지를 업로드하면 영양소 정보를 예측하고 분석합니다.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "v2EpRgAxU9qL",
        "outputId": "b6819a74-820a-4edb-b4b3-29f097314452"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://65c527ef29c65a5ef5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://65c527ef29c65a5ef5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    }
  ]
}