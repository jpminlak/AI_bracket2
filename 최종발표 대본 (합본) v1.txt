#1 (김유진) 표지
안녕하세요.
'스마트 음식 영양 분석 및 식단 추천 프로젝트' 발표를 맡은 김유진입니다.
저희 프로젝트는 CNN 모델을 활용한 사진 분석과 LLM 모델을 통한 텍스트 생성을 기반으로 사용자에게 최적화된 음식 영양 분석 및 식단 추천 서비스에 대해 발표 시작하겠습니다.

#2 목차
발표 순서는 목차에 보이는 순서대로 진행하겠습니다. 뒤에서 각각 자세히
설명드리겠습니다.

#3 1. 개요 및 현황
먼저 프로젝트의 개요 및 현황을 말씀드리겠습니다. 저희 팀 주제는 'AI 기반 음식 영양 분석 & 식단 추천 서비스'입니다.
이 프로젝트의 주요 배경 및 목적으로는 4가지입니다
첫째, 개인별 섭취 영양 분석입니다.
사용자의 실제 영양 섭취 상황을 분석하고 적절한 섭취량을 제안하는 것입니다.
두 번째는 분석된 데이터를 바탕으로 사용자에게 최적화된 식단을 추천하는 것입니다.
세번째 사용자의 성향이나 기분에 따른 다양한 식단 제안을 통해 만족감을 높이는
것입니다.
마지막으로는 LLM과 머신러닝을 활용하여 사용자의 상태에 맞는 영양소 섭취와 식단
추천을 제공하는 것입니다.
주요 기능으로는 맞춤형 섭취량 제안, 기분과 취향에 따른 식단 제안, 개인별 식단 관리,
그리고 개인정보 보안 기능이 있습니다.
이 기능들을 통해 사용자에게 보다 정확하고 개인화된 서비스를 제작했습니다.

#4 2. 팀원별 역할 분담
다음은 저희 팀원별 역할 분담입니다.
먼저 팀장인 박정환님은 프로젝트 총괄(PM), 진행, 테스터, DB 및 웹페이지 구성, 그리고
회원 관리를 담당하고 있습니다.
부팀장인 김도윤님은 주제 선정, 프로젝트 기획, 그리고 식단 추천을 위한 LLM 모델 개발을
맡고 있습니다.
강성대님은 기술 총괄로서 프로젝트 구조 설계, 사진 분석을 위한 CNN 모델 개발, 그리고 AI
학습 및 예측 부분을 담당하고 있습니다.
이동훈님은 KoBERT(코버트) 감정 분석과 Gemini LLM을 연동하여 감정 기반 맞춤 추천
기능을 구현하고 있습니다.
마지막으로 김유진 저는 보고서 총괄과 함께 사진 분석을 위한 CNN 모델 학습, 그리고
그리고 FastAPI 서버 연동을 통한 음식 분석 기능을 담당하고 있습니다.

#5 3. 개발 환경 (프론트엔드, 백엔드)
다음은 개발 환경입니다.
프론트엔드에서는 HTML과 CSS로 웹 구조와 스타일을 구현했고, javascript로 동적인
기능을 구현했습니다.
Spring security와 DB연동을 위해 Thymeleaf를 사용했습니다.
백엔드에서는 Spring Boot를 사용해 웹 애플리케이션을 개발했고 , Java로 비즈니스
로직을 작성했습니다.
빌드 도구로는 Groovy 사용했습니다.
DB는 MariaDB를 사용하며, JPA를 통해 객체와 테이블을 매핑했습니다.
또한, 계정 보안 강화를 위해 Spring Security를 적용했습니다.

#6 3. 개발 환경 (AI/ML)
예측 모델 구현에는 Python을 사용했고, FastAPI를 통해 백엔드와 통신하고 있습니다.
LLM 모델로는 Ollama를 활용했습니다.
사진 분석 전처리에는 MobileNet V2 (모바일넷 브이투) 를 사용했고, 학습 모델로는
EfficientNetB0 (이피션트넷 비 제로) 를 채택했습니다.
감정 분석에는 KoBERT (코버트) 를 사용했고, 외부 API로는 Gemini API를 활용했습니다.

#7 4. 프로젝트 일정 계획
다음은 프로젝트 일정계획입니다.
저희는 8월 18일부터 9월 15일]까지의 기간 동안 프로젝트를 진행하고 있으며, 현재 75%
정도 진행되었습니다.
사진 분석 모델 학습과 FastAPi연동, 그리고 LLM기능까지 구현 완료 하였고 남은 기간동안
식단 추천 및 저장하는 기능까지 진행할 예정입니다. 현재까지는 계획된 일정에 맞춰
순조롭게 진행되고 있으며, 남은 기간 동안에도 효율적인 자원 배분과 팀원 간의 긴밀한
협력을 통해 목표를 달성할 수 있도록 최선을 다하겠습니다.

===================================================================

#8~10 (박정환)
이번에는 기능 정의서입니다.
각 분류별로 들어갈 기능에 대한 설명입니다.
회원관리, 웹페이지, 음식과 식단 추천, AI 예측 모델, 데이터베이스 등에 대한 요구사항을 정리하였습니다.

#11
정책 정의서에는 주로 회원정보에 대한 내부 규약을 정리하였습니다.
서비스 내용과 직접적인 연관을 갖기보다는 사이트 운영 정책에 대한 설명이라고 할 수 있습니다.

#12~14
전체 프로젝트의 개발 코드가 어떤 구조로 되어있는지에 대한 구조도입니다.
크게 Spring Boot와 Python으로 나누어 구성하였습니다.
Spring Boot에서는 java와 html, 그리고 Gradle 등에 대한 환경 설정을 하고, 컨트롤러와 뷰를 연결시키는 작업을 수행했습니다.
Python에서는 CNN, LLM 모델 학습 등을 수행하고, 그 결과를 뷰로 표시하는 역할을 맡겼습니다.

#15
실제 사용자가 웹사이트를 이용할 때 마주하게 될 메뉴 구조도입니다.
크게 주요 기능, 회원 관리, 고객 지원으로 나누었습니다.

#16
사용자의 명령을 받은 프로그램은 내부적으로 컨트롤러를 거쳐 각 기능에 해당하는 인공지능 모델의 학습 결과를 토대로 데이터베이스와 연결합니다.
LLM 학습의 경우, 추가로 API를 통해 수정된 자료를 접속하여 기존 학습 결과를 보정하는 과정을 추가하였습니다.

#17~18
 이 서비스에 사용한 DBMS의 구조를 나타낸 관계도입니다.
 논리적ERD와 물리적ERD로 분리해 정리해 봤습니다.
 주요 데이터베이스 엔티티에는 회원을 관리하는 member, 식품 정보를 저장하는 food, 식단 정보를 저장하는 diet 등이 있습니다.

===================================================================

#19 (강성대)
"안녕하십니까. 저는 이번 프로젝트에서 AI 기반의 음식 인식 모델 개발을 담당했습니다.
먼저, 경량 합성곱 신경망인 MobileNetV2를 활용한 모델 개발에 대해 설명드리겠습니다.
저희는 Food Images(Food-101) 데이터셋을 활용하여 101개의 클래스와 총 101,000장의 이미지를 훈련 데이터와 검증 데이터로 8대2 비율로 분할했습니다.
모델 구성에서는 전이 학습(Transfer Learning) 기법을 적용했습니다.
이미 학습된 ImageNet 가중치를 가져와 미세 조정하여 모델의 초기 성능을 높였습니다.
보시는 코드처럼 MobileNetV2를 base_model로 사용하고, 그 위에 GlobalAveragePooling2D와 Dense 레이어를 추가하여 최종 분류를 수행하도록 설계했습니다.

모델 학습 설정으로는 Adam 옵티마이저를 사용했고, 학습률은 1e-5로 설정하여 미세 조정을 진행했습니다.
에포크는 20회로 설정했으며, EarlyStopping 콜백을 적용하여 과적합을 방지하고 최적의 학습 시점에서 훈련을 멈추도록 했습니다."

#20
"MobileNetV2 모델의 학습 진행 결과입니다.
14 에포크에서 EarlyStopping이 예정보다 일찍 학습을 종료했습니다.
오른쪽 그래프를 보시면, 'Training Accuracy'와 'Validation Accuracy'는 훈련이 진행될수록 증가하는 반면, 'Training Loss'와 'Validation Loss'는 감소하는 추세를 보입니다.
하지만 'Training Accuracy'와 'Validation Accuracy' 간의 간격이 벌어지고, 'Training Loss'는 계속 감소하지만 'Validation Loss'는 특정 시점부터 더 이상 감소하지 않는 현상을 볼 수 있습니다.
이는 모델이 훈련 데이터에 너무 특화되어 새로운 데이터에 대한 일반화 성능이 떨어진, 즉 **과적합(Overfitting)**이 발생했다는 것을 의미합니다.
검증 정확도는 0.7177로 나타났습니다."

#21
"이러한 과적합 문제를 해결하기 위해 데이터 증강(Data Augmentation) 기법을 적용했습니다.
보시는 바와 같이 RandomFlip, RandomRotation, RandomZoom, RandomContrast 등을 활용하여 훈련 데이터의 다양성을 늘렸습니다.
또한, 모델의 Dropout 레이어 비율을 0.5로 높여 과적합을 추가적으로 방지하고자 했습니다.
하지만 데이터 증강과 Dropout을 적용한 결과, 오히려 정확도가 크게 떨어지는 문제가 발생했습니다.
이는 미세 조정 단계의 학습률 문제이거나, 데이터셋 자체에 문제가 있을 가능성을 시사했습니다."

===================================================================

#22 MobileNetV2 모델 (2) - AI HUB 데이터셋 활용
안녕하십니까. 다음으로 MobileNetV2 모델로 AI HUB에서 제공하는 음식 이미지
데이터셋을 활용했습니다. 이 데이터셋은 총 12개의 음식 클래스와 2,159장의 이미지로
구성되어 있습니다. 이 데이터를 훈련 데이터와 검증 데이터로 8대 2의 비율로 분할하여
모델 학습에 사용했습니다.
모델 구성은 이전과 동일하게 전이 학습(Transfer Learning)을 적용했습니다. 이는
이미지넷(ImageNet)으로 사전 학습된 가중치를 활용하여 학습 시간을 단축하고 효율성을
높이는 방법입니다. 학습 환경 설정 또한 이전과 동일하게 Adam 옵티마이저, 초기 학습률
1e-5, 20 에포크, 그리고 과적합 방지를 위한 EarlyStopping을 적용했습니다.
이러한 변경을 통해 과적합 문제를 해결하고 모델의 성능을 개선하고자 했습니다.

#23 MobileNetV2 모델 (2) - 학습 진행 및 결과
다음으로 AI HUB 데이터셋을 활용한 MobileNetV2 모델의 학습 진행 상황과 그 결과를
시각화 자료와 함께 설명드리겠습니다.
저희는 총 16개 에포크에 걸쳐 모델 학습을 진행했으며, EarlyStopping이 적용되어 예정된
에포크보다 일찍 학습이 종료되었습니다. 시각화된 그래프를 보시면, 훈련 손실은 꾸준히
감소하는 경향을 보였지만, 검증 손실은 감소하지 않거나 오히려 증가하는 경향을
보였습니다. 이는 모델이 여전히 훈련 데이터에 과적합되고 있음을 시사합니다.
구체적인 수치를 살펴보면, 훈련 데이터에 대한 정확도는 약 97.8%로 매우 높게
나타났습니다. 하지만 검증 데이터에 대한 정확도는 약 87.1%로, 훈련 정확도에 비해 다소
낮은 수치를 보였습니다. 이는 모델이 훈련 데이터에 너무 특화되어 새로운 데이터에 대한
일반화 성능이 떨어진다는 것을 의미합니다.
결론적으로, 이 모델은 높은 정확도를 보였지만, 사용된 데이터셋의 클래스 수가 12개로
적다는 한계점을 가지고 있습니다. 클래스 수가 적으면 모델이 다양한 상황에 대한 학습이
부족해져 일반화 성능이 저하될 수 있습니다. 따라서 다음 단계에서는 이러한 한계를
극복하기 위한 추가적인 노력이 필요하다고 판단했습니다.

===================================================================

#24 (강성대)
"이어서, 경량 컨볼루션 신경망 중 또 다른 모델인 EfficientNetB0를 활용한 개발 과정입니다.
이 모델도 Food Images(Food-101) 데이터셋을 사용했습니다.
EfficientNetB0를 base_model로 사용하고, 마찬가지로 GlobalAveragePooling2D와 Dense 레이어를 추가했습니다.
모델 구성에서는 전이 학습과 함께 Dropout 레이어를 추가하여 과적합을 방지했습니다.
또한, Adam 옵티마이저를 기본 학습률(0.001)로 사용하고, 에포크는 20회, 그리고 EarlyStopping을 적용했습니다.
하지만 학습 진행 결과, 11번째 에포크부터 과적합이 시작되어 EarlyStopping으로 인해 학습이 중단되었습니다.
최종 검증 정확도는 0.6914로 다소 낮은 결과가 나왔습니다."

#25
"EfficientNetB0 모델의 미세 조정 단계입니다.
EarlyStopping 외에 ReduceLROnPlateau 콜백을 추가하여, 검증 손실이 일정 기간 동안 개선되지 않으면 학습률을 자동으로 감소시키도록 설정했습니다.
또한, 모델의 마지막 20개 레이어만 훈련 가능하도록(base_model.trainable = True, fine_tune_at = -20) 설정하여 미세 조정을 수행했습니다.
미세 조정 후 학습 결과, 훈련/검증 데이터에 대한 과적합이 이전보다 줄어들었습니다.
검증 데이터 손실은 0.9239, 검증 데이터 정확도는 0.7653을 기록했습니다.
이는 초기 학습보다 개선된 결과이며, 조기 종료가 학습 결과 향상에 도움이 되었음을 보여줍니다."

#26
"EfficientNetB0 모델의 1차 학습과 미세 조정 후의 학습 결과 그래프를 비교한 것입니다.
왼쪽의 1차 학습 결과 그래프를 보면, Training Loss와 Validation Loss 모두 초기에 크게 감소하다가 Validation Loss가 다시 증가하는 과적합 경향이 보입니다.
반면, 오른쪽 미세 조정 후 학습 결과 그래프를 보면 Training Loss와 Validation Loss가 비교적 꾸준히 감소하며 수렴하는 모습을 보입니다.
Training Accuracy와 Validation Accuracy도 안정적으로 상승하는 것을 확인할 수 있습니다.
이를 통해 미세 조정과 학습률 조절을 통해 모델의 안정성과 일반화 성능이 향상되었음을 알 수 있습니다."

#27
"마지막으로 객체 탐지 모델인 YOLOv8n을 활용한 음식 탐지 모델 개발입니다.
저희는 Roboflow에서 'food-detection-fme3o' 프로젝트의 'yolov8n' 데이터셋을 다운로드하여 사용했습니다.
이 데이터셋은 바운딩 박스 라벨링이 완료된 이미지들을 YOLOv8 형식으로 제공합니다.
YOLOv8n 모델은 이미 훈련된 가중치를 로드하여 사용했으며, 에포크 100회, patience 50회 설정으로 학습을 진행했습니다.
학습 결과를 통해 Precision, Recall, mAP50 등의 성능 지표를 그래프로 시각화했습니다."

#28
"YOLOv8n 모델의 학습 결과와 시각화입니다.
왼쪽의 그래프들은 훈련 및 검증 손실, Precision, Recall, mAP50 지표의 변화를 보여줍니다.
모두 전반적으로 안정적으로 수렴하는 경향을 확인할 수 있습니다.
특히 오른쪽의 F1-스코어 곡선을 보면, F1-스코어가 가장 높은 지점(Confidence Threshold 0.4 근처)에서 Precision과 Recall의 균형이 가장 좋음을 알 수 있습니다.
이 모델은 Precision 0.810, Recall 0.778, mAP50 0.814의 성능을 보였습니다.
YOLOv8n을 통해 음식 객체를 정확하게 탐지하고 분류하는 능력을 확보할 수 있었습니다.
이를 통해 사용자가 음식 사진을 올렸을 때, 여러 음식이 한 장면에 있더라도 개별 음식들을 인식하고 영양 정보를 제공하는 데 활용할 수 있습니다."

===================================================================

#29 (김도윤; 실제 발표 박정환)
이번에는 LLM 모델과 API에 대해 말씀드리겠습니다.
LLM 모델로는 Ollama를 사용했으며, qwen2.5:3b-instruct 버전으로 학습을 수행했습니다.
이 모델은 사용자의 프로필 정보를 바탕으로 하루 식단을 자동으로 추천해 주는 역할을 합니다.

API 호출은 POST /recommend?live=true|false 방식으로 이루어지는데요, live=true일 때는 LLM을 직접 호출해서 응답을 받습니다.
만약 live=false이거나, LLM 호출에 실패하거나, 응답 형식이 맞지 않을 경우에는 미리 준비된 Fallback JSON을 반환해서 서비스가 끊기지 않도록 안정성을 확보했습니다. 
//내부적으로는 {OLLAMA_HOST}/api/generate 엔드포인트를 통해 LLM API를 호출하고, temperature:0.8, repeat_penalty:1.1 같은 옵션들을 설정해서 응답의 다양성과 품질을 조절하고 있습니다. OLLAMA_HOST와 OLLAMA_MODEL 같은 환경 변수를 사용해서 유연하게 관리하고 있다는 점도 특징입니다.

#30
활용순서로서는 먼저 사용자의 성별, 키, 몸무게 같은 DB 프로필 정보를 활용해서 하루 식단을 자동으로 추천해 줍니다.
이를 위해 Mifflin BMR 공식을 사용해 기초대사량을 계산하고, 여기에 활동 계수 1.375를 곱해서 총 일일 에너지 소비량(TDEE)을 산출한 다음, 최종 목표 칼로리를 정하게 됩니다.
이렇게 산출된 목표 칼로리를 기준으로 아침, 점심, 저녁 식사에 각각 30%, 40%, 30%의 비율로 칼로리를 배분하고, 각 끼니별로 단백질, 탄수화물, 지방, 섬유질 같은 영양소도 함께 계산합니다.
LLM 호술에 성공할 경우 LLM을 통해 실시간으로 식단을 생성하고, 그렇지 않거나 문제가 생기면 Fallback 로직으로 바로 식단을 제공해서 사용자 경험을 매끄럽게 유지하고 있습니다.

#31
그 다음, 사용자 입력 데이터를 모델이 처리하기 쉬운 형태로 정규화하는 과정을 거칩니다.
앞서 말씀드린 BMR과 TDEE 계산을 통해 사용자의 목표 칼로리를 설정하고, 각 끼니별로 목표 칼로리를 배분합니다.
이어서, 옵션에 따라 LLM을 호출해서 식단 JSON 응답을 받습니다.
수신된 식단 데이터는 단위 제거 및 리스트화 과정을 거쳐 다시 한번 정규화되고, 각 끼니의 영양소를 합산합니다.
마지막으로, 목표 칼로리 대비 ±200kcal 범위 내에서 식단을 스케일링하고, 왜 이런 식단이 추천되었는지에 대한 이유(reason)를 생성해서 사용자에게 제공합니다.
이 모든 과정을 통해 개인에게 최적화된 식단 추천이 이루어지는 것이죠.

#32
API의 내부 처리 과정에서 요청을 보낼 때는 사용자의 성별, 연령, 신장, 체중 정보를 JSON 형태로 전달합니다.
그러면 각 끼니별 식단 정보, 총 칼로리 등의 영양소, 그리고 추천 이유를 포함하는 JSON 객체를 응답과정에서 반환합니다.
모든 통신은 Content-Type: application/json으로 이루어져 데이터의 일관성과 호환성을 유지하고 있습니다.

#33
LLM 호출이 실패하거나, 응답 형식이 맞지 않거나, 타임아웃이 발생할 경우에는 동일한 스키마를 가진 Fallback JSON을 반환해서 서비스가 중단되지 않도록 하고 있습니다.
사용자에게 결과를 보여주기 전에는 스키마 검증과 숫자 파싱 과정을 거쳐 데이터의 유효성을 꼼꼼하게 확인합니다.
모델의 품질 지표로는 목표 칼로리 오차(±200kcal 이내), Fallback 비율, LLM 활성화 여부에 따른 응답 시간, 그리고 추천 식단의 스타일 일관성을 중요하게 관리하고 있습니다.
이러한 노력들을 통해 사용자분들께 안정적이고 신뢰할 수 있는 식단 추천 서비스를 제공하고자 최선을 다했습니다.

#34
저희는 LLM이 사용자에게 가장 적합한 식단을 추천할 수 있도록 몇 가지 중요한 규칙을 설정했습니다.
첫째, 한 끼에는 한 가지 스타일(한식 밥상, 면, 빵·양식, 샐러드 볼, 일식 중 1가지)만 사용하도록 제한했습니다. 이는 식단의 일관성과 균형을 유지하기 위함입니다.
둘째, 끼니 간 메인 메뉴의 중복을 피해서 사용자에게 더 다양한 식단 경험을 제공합니다.
셋째, 한국 사용자에게 친숙한 1~4개의 아이템으로 메뉴를 구성해서 현실적이고 실용적인 식단 추천을 목표로 합니다.
넷째, 목표 칼로리 ±200kcal 범위 내에서 식단을 허용하며, 마지막으로 응답은 반드시 JSON 형식으로만 반환하도록 해서 저희 시스템과의 연동성을 높였습니다.
이러한 규칙들을 통해 LLM이 더욱 정교하고 실용적인 식단을 제안할 수 있도록 설계했습니다.

===================================================================================

#35 (이동훈)
“저희는 한국어에 특화된 KoBERT 모델을 사용했습니다.
이 모델은 문장을 분석해서 공포, 놀람, 분노, 슬픔, 중립, 행복, 혐오 이렇게 7가지 감정으로 분류합니다.
감정 분석 결과를 기반으로 Gemini API와 연동하여 사용자 맞춤형 음식 추천을 제공합니다.”

📌 36번 슬라이드 – 텍스트 감정 분석의 이해

“KoBERT 모델은 이미 학습이 완료된 상태라, 추가 학습 과정 없이 바로 활용할 수 있습니다.
사용자가 입력한 텍스트를 분석해서 가장 적합한 감정을 분류하고, 그 감정 결과가 식단 추천의 출발점이 됩니다.”

📌 37번 슬라이드 – 데이터 전처리

“감정 분석을 위해서는 텍스트를 숫자로 변환하는 과정이 필요합니다.
토크나이저가 문장을 숫자 배열로 바꿔주고, 모든 문장은 길이를 256자로 맞춰줍니다.
그 결과 최종적으로 모델이 이해할 수 있는 텐서 형태로 변환되어 감정 분류에 사용됩니다.”

📌 38번 슬라이드 – 정확도 향상 전략

“예측의 신뢰도를 높이기 위해 규칙 기반 보정 로직을 추가했습니다.
예를 들어, ‘너무 무섭지 않아’라는 문장에서 ‘무섭’이라는 키워드만 보면 공포로 분류될 수 있지만, 뒤의 ‘않아’를 인식해 중립이나 슬픔으로 보정할 수 있도록 했습니다.
이런 보정 과정을 통해 잘못된 감정 분류를 줄였습니다.”

📌 39번 슬라이드 – 음식 추천 로직

“마지막으로 감정 분석 결과를 음식 추천에 연결했습니다.
우리는 감정을 벡터 형태로 저장한 데이터베이스를 활용합니다.
사용자의 감정과 유사한 벡터를 검색한 뒤, 그 결과를 Gemini API에 전달해 프롬프트를 강화합니다.
최종적으로 Gemini가 감정에 맞는 음식 3가지를 추천해 줍니다.
즉, 사용자의 감정이 ‘행복’이면, 행복한 기분을 더 높여주는 메뉴를 제안하는 식입니다.”

===================================================================================

#40 (박정환)
 주요 서비스 화면 및 기능에 대한 설명을 시작하겠습니다.
 가장 먼저 만나게 될 MealMind의 메인 화면에 대한 소개입니다.
 메인 화면에서는 회사 소개와 이미지 정립을 위한 디자인 구성을 하고 있습니다.

 모든 웹페이지에는 header와 footer가 공통으로 들어갑니다.
 이곳에 모든 메뉴를 상시로 노출시켜 어느 페이지에 가도 모든 서비스를 이용할 수 있게 웹페이지를 구성하였습니다.
 우선 header의 제일 왼쪽에는 환영문구가 나오는데, 잠시 후 로그인을 한 이후로는 회원의 이름이 표시될 수 있게 하였습니다.
 가운데에는 각 메뉴에 해당하는 링크가 있으며, 오른쪽에는 회원정보, 로그인, 회원가입 버튼을 배치하였습니다. 로그인 버튼은 로그인 이후에는 로그아웃 버튼으로 바뀝니다.
 화면 아래부분에는 이용약관, 문의하기, 공지사항 등 고객지원에 해당하는 링크들이 있습니다.

#41
 서비스를 이용하기 위해서는 회원가입이 필요합니다.
 여기서 회원 정보를 입력하고 가입을 누르면 MealMind의 모든 서비스를 이용하실 수 있습니다.
 비밀번호를 두 번 입력하는데, 앞선 비밀번호와 비밀번호 확인에 입력한 비밀번호가 다르다면 가입할 수 없습니다.
 이메일과 전화번호는 선택사항이지만, 문의하기 기능을 이용하기 위해서는 이메일을 등록해야만 가능합니다.

#42
 로그인 화면입니다.
 회원의 로그인 정보와 상태에 대한 정보는 Spring Security로 관리합니다.
 만약 로그인 버튼이 아닌 다른 로그인이 필요한 메뉴를 클릭한다면 자동으로 로그인 화면으로 넘어오면서 가운데 별도의 초록색 메시지를 표시합니다.
 등록한 계정과 비밀번호가 일치하면 로그인이 됩니다.
 로그인 실패시 로그인 버튼 하단에 별도의 빨간색 메시지를 표시합니다.

===================================================================

#43~44 (강성대)

===================================================================

#45 (김도윤; 실제 발표 박정환)
이번에는 식단 추천 화면입니다.
이 화면은 사용자가 자신의 식단을 확인하고 새로운 식단을 추천받을 수 있는 MealStaff의 핵심 기능 중 하나입니다.
화면 상단에는 오늘 날짜와 사용자의 닉네임이 표시되어 개인화된 느낌을 줍니다.
화면 중앙에는 아침, 점심, 저녁 각 식사 시간에 섭취한 음식과 그에 따른 영양소 정보가 상세하게 나타납니다.
또한, 해당 일자에 섭취한 총 칼로리 정보도 한눈에 확인할 수 있습니다.
사용자는 화면 하단의 '추천 받기' 버튼을 클릭해서 자신의 성별, 나이, 키, 몸무게 등의 정보를 기반으로 맞춤형 식단을 추천받을 수 있습니다.

#46
상기한 정보를 바탕으로 다음 식사 시간에 맞춘 식단을 추천한 결과입니다.
아침에 먹은 음식을 등록하면 점심 식사를, 저녁에 먹은 음식을 등록하면 다음날 아침 식사를 추천합니다.

당일 권장 영양소 섭취량을 넘지 않을 경우, 권장량에 맞춰 식단을 추천합니다.
이미 권장량을 초과한 경우, 다이어트를 권하며 식단은 추천하지 않습니다.
이 화면을 통해 사용자분들은 자신의 건강 목표에 맞춰 식단을 손쉽게 관리하고 개선해 나갈 수 있습니다.

#47
추천받은 식단을 저장하면 회원별 기록을 통해 다시 확인하실 수 있습니다.

#48
화면 표시는 달력 형태, 또는 날짜별로 정리한 게시판 형태로 볼 수 있습니다.

#49
개별 일자 기록을 누르면 식사시간 별 상세 정보를 볼 수 있습니다.

===================================================================================

📌 50번 슬라이드 – 화면 설명 (이동훈)
감정분석 식단추천 화면에 대해 설명드리겠습니다.
이 화면은 사용자의 현재 기분이나 취향에 따라 맞춤형 식단을 추천해주는 기능입니다.
사용자는 V1에 표시된 텍스트 입력란에 자신의 기분을 자연어로 입력할 수 있습니다.
예를 들어, "오늘 너무 스트레스 받아서 매운 음식이 당겨요"와 같이 입력할 수 있습니다.
사용자가 텍스트를 입력하고 A1 버튼, 즉 '확인' 버튼을 누르면, 입력된 텍스트는 서버로 전송되어 앞서 설명드린 AI 모델이 분석하게 됩니다. 분석 결과에 따라 D1에 표시된 것처럼 사용자의 취향과 기분에 맞는 추천 식단 텍스트가 출력됩니다. 이 기능을 통해 사용자는 자신의 감정 상태에 가장 적합한 음식을 쉽고 편리하게 추천받을 수 있습니다.

===================================================================================

#51~53 (박정환)
 단위별 테스트에 대한 설명입니다.
 각 기능에 대한 기본적인 테스트들을 진행하였습니다.
 회원가입 기능, 사진 업로드, 문장 입력 등과 같이 여러 가지 상황이 가능한 기능들의 경우, 예상 가능한 상황들을 모두 반복해가며 성공과 실패 사례들을 확인하였습니다.
 메인 페이지 출력, 회원 가입, 로그인, 사진 업로드 테스트 등을 이 작업을 통해 수행하였습니다.
 단위별 테스트를 통해 각 기능이 본래 의도했던 대로 작동하는 것을 확인할 수 있었습니다.
 
#54~56
 통합 테스트입니다.
 전체 시스템이 올바르게 작동하는 지 확인하는 테스트로써, 개별 단위 테스트에서 검증된 기능들이 함께 동작하거나 다음 순서가 순차적으로 작동하는 지를 확인하는 과정이었습니다.
 특히 실제 사용자 경험에 촛점을 두고 진행하며 각 과정간의 연결이 자연스러운 지를 검증하였습니다.
 로그인이 필요한 서비스를 클릭할 시 자동으로 로그인 페이지로 넘어가는지, 사진 분석 결과를 DB에 저장하고 이를 식단 추천 페이지에 자동으로 표시하는지, 그리고 이 데이터를 바탕으로 식단 추천 기능이 의도대로 작동하는지를 확인하였습니다.
 
#57
이번에는 주요기능을 실제로 실행해본 시연영상입니다.
영상 길이는 약 2분입니다.
 

* 끝인사

=========================================================

cf.) 발표 당일 김도윤은 취업 면접으로 인해 불참. 해당 대본은 박정환이 발표. 해당 부분 다소 수정.