{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWR1FrjzOSpC",
        "outputId": "a77ad4cb-c1d7-4a36-a899-fcf5ab5c4176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow pandas Pillow gradio numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "kfooddb = pd.read_csv('food.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "iXJqsdgcOWSy"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°ì¡´ì˜ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n"
      ],
      "metadata": {
        "id": "O0zTxDKyOc8h"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ë¡œë”© ë° ì œë„ˆë ˆì´í„° ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)\n",
        "data_dir = '/content/foodImage'\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],        # ë°ê¸° ë²”ìœ„ ì„¤ì •\n",
        "    channel_shift_range=50,             # ì±„ë„(ìƒ‰ìƒ) ë³€í˜• ì„¤ì •\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "pZqUt08VOlz-"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmCniYeKPh8Y",
        "outputId": "3c44ee01-0e1e-4ddc-929a-fbbc9476cc91"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2102 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdpzFYKzPj1u",
        "outputId": "41704eea-7636-4c84-cc60-e454320a2f13"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 520 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---\n",
        "# 3. ë¼ë²¨ ë¶ˆì¼ì¹˜ ìˆ˜ì •\n",
        "# ImageDataGeneratorê°€ ì°¾ì€ í´ë˜ìŠ¤ ì´ë¦„ì„ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"ëª¨ë¸ì´ ì¸ì‹í•œ ìŒì‹ ë¼ë²¨:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q_YBSfsVeqC",
        "outputId": "ca38c638-d5c0-46a5-fbdd-cbab4ab1a699"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ì´ ì¸ì‹í•œ ìŒì‹ ë¼ë²¨: ['.ipynb_checkpoints', 'ê³ ì‚¬ë¦¬ë‚˜ë¬¼', 'ê³±ì°½ì „ê³¨', 'ê¹€ì¹˜ì „', 'ê¹ë‘ê¸°', 'ë‹¬ê±€êµ­', 'ë‹¬ê±€ë§ì´', 'ë¼ì§€ê°ˆë¹„', 'ì–‘ë…ì¹˜í‚¨', 'ì „ë³µì£½', 'í˜¸ë°•ì „', 'í›ˆì œì˜¤ë¦¬']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. í›ˆë ¨ ê°€ëŠ¥í•œ ë ˆì´ì–´ ìˆ˜ ì¡°ì • (í•µì‹¬ ë³€ê²½ ë¶€ë¶„)\n",
        "# MobileNetV2 ê¸°ë°˜ ëª¨ë¸ êµ¬ì¶•\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n"
      ],
      "metadata": {
        "id": "uEV1RylzBvaQ"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-45:]:\n",
        "    layer.trainable = True\n"
      ],
      "metadata": {
        "id": "szGQ0tKVPn-2"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ìƒˆë¡œìš´ ë¶„ë¥˜ ë ˆì´ì–´ ì¶”ê°€ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "NSbMwlQsB11b"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "    \"balanced\",\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "gK2fF3V7prKz"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# 2. EarlyStopping ì½œë°± ì„¤ì • (í•µì‹¬ ë³€ê²½ ë¶€ë¶„)\n",
        "callbacks = [\n",
        "    # patienceë¥¼ 3ìœ¼ë¡œ ì¤„ì—¬ ëª¨ë¸ì´ ë¹ ë¥´ê²Œ ê³¼ì í•©ë˜ê¸° ì „ì— í›ˆë ¨ì„ ì¤‘ë‹¨\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    # ReduceLROnPlateau ì„¤ì •ì€ ìœ ì§€\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "]\n"
      ],
      "metadata": {
        "id": "Z6wYQyD5cPxY"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ëª¨ë¸ì´ ì¸ì‹í•œ ìŒì‹ ë¼ë²¨:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NPhL9c2qqCT",
        "outputId": "d98809af-f507-4767-ece9-fe4d94ce338b"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ì´ ì¸ì‹í•œ ìŒì‹ ë¼ë²¨: ['.ipynb_checkpoints', 'ê³ ì‚¬ë¦¬ë‚˜ë¬¼', 'ê³±ì°½ì „ê³¨', 'ê¹€ì¹˜ì „', 'ê¹ë‘ê¸°', 'ë‹¬ê±€êµ­', 'ë‹¬ê±€ë§ì´', 'ë¼ì§€ê°ˆë¹„', 'ì–‘ë…ì¹˜í‚¨', 'ì „ë³µì£½', 'í˜¸ë°•ì „', 'í›ˆì œì˜¤ë¦¬']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "djnHW_tpPqop"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit() í•¨ìˆ˜ì—ì„œ epochs ê°’ì„ ë³€ê²½í•˜ì„¸ìš”.\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9X-Dp9rPtO7",
        "outputId": "b8a9fbe9-45c8-44dd-e4fe-ee83f93778af"
      },
      "execution_count": 212,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.2591 - loss: 2.3132 - val_accuracy: 0.5115 - val_loss: 1.4994 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.6853 - loss: 0.9442 - val_accuracy: 0.5885 - val_loss: 1.4159 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - accuracy: 0.8075 - loss: 0.6154 - val_accuracy: 0.6135 - val_loss: 1.3792 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.8315 - loss: 0.5137 - val_accuracy: 0.6096 - val_loss: 1.4036 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.8703 - loss: 0.4098 - val_accuracy: 0.6269 - val_loss: 1.2964 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.8692 - loss: 0.3939 - val_accuracy: 0.6808 - val_loss: 1.1575 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.9086 - loss: 0.2893 - val_accuracy: 0.6615 - val_loss: 1.1686 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9131 - loss: 0.2418 - val_accuracy: 0.6538 - val_loss: 1.2843 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.9187 - loss: 0.2365 - val_accuracy: 0.7135 - val_loss: 0.9947 - learning_rate: 5.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.9460 - loss: 0.1831 - val_accuracy: 0.7327 - val_loss: 0.9322 - learning_rate: 5.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9399 - loss: 0.1815 - val_accuracy: 0.7442 - val_loss: 0.8590 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.9453 - loss: 0.1545 - val_accuracy: 0.7712 - val_loss: 0.7954 - learning_rate: 5.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9569 - loss: 0.1374 - val_accuracy: 0.7558 - val_loss: 0.8086 - learning_rate: 5.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9581 - loss: 0.1363 - val_accuracy: 0.7731 - val_loss: 0.7369 - learning_rate: 5.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9489 - loss: 0.1374 - val_accuracy: 0.7885 - val_loss: 0.7210 - learning_rate: 5.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9646 - loss: 0.1233 - val_accuracy: 0.7962 - val_loss: 0.7518 - learning_rate: 5.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.9697 - loss: 0.1064 - val_accuracy: 0.8154 - val_loss: 0.6098 - learning_rate: 5.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.9657 - loss: 0.1045 - val_accuracy: 0.8038 - val_loss: 0.6049 - learning_rate: 5.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.9598 - loss: 0.1243 - val_accuracy: 0.8077 - val_loss: 0.6214 - learning_rate: 5.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9711 - loss: 0.0874 - val_accuracy: 0.7981 - val_loss: 0.7533 - learning_rate: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# 3. ë¼ë²¨ ë¶ˆì¼ì¹˜ ìˆ˜ì •\n",
        "# ImageDataGeneratorê°€ ì°¾ì€ í´ë˜ìŠ¤ ì´ë¦„ì„ ì§ì ‘ ì‚¬ìš©\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"ëª¨ë¸ì´ ì¸ì‹í•œ ìŒì‹ ë¼ë²¨:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBrTdUTl-Y4U",
        "outputId": "cee47297-ee41-4eb4-b920-7937b9312d6e"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ì´ ì¸ì‹í•œ ìŒì‹ ë¼ë²¨: ['.ipynb_checkpoints', 'ê³ ì‚¬ë¦¬ë‚˜ë¬¼', 'ê³±ì°½ì „ê³¨', 'ê¹€ì¹˜ì „', 'ê¹ë‘ê¸°', 'ë‹¬ê±€êµ­', 'ë‹¬ê±€ë§ì´', 'ë¼ì§€ê°ˆë¹„', 'ì–‘ë…ì¹˜í‚¨', 'ì „ë³µì£½', 'í˜¸ë°•ì „', 'í›ˆì œì˜¤ë¦¬']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history ê°ì²´ì—ì„œ ì •í™•ë„ì™€ ì†ì‹¤ ê°’ í™•ì¸\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "print(\"Training Accuracy:\", train_accuracy[-1])\n",
        "print(\"Validation Accuracy:\", val_accuracy[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da5QPwv6DOe-",
        "outputId": "cf088fd0-cb30-4bb0-9dd5-59170a56df68"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9690770506858826\n",
            "Validation Accuracy: 0.7980769276618958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('foodim9.keras')"
      ],
      "metadata": {
        "id": "6CVZbmPhANKs"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ì–‘ DB ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
        "nutrition_db = pd.read_csv('/content/food.csv', encoding='UTF-8')\n",
        "model = tf.keras.models.load_model(\"foodim6.keras\")"
      ],
      "metadata": {
        "id": "FUR3Ehuy-c-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio í•¨ìˆ˜ ìˆ˜ì •\n",
        "def predict_and_analyze_nutrition(img_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    predicted_food_name = class_names[predicted_class_index]\n",
        "\n",
        "    nutrition_info = nutrition_db[nutrition_db['ìŒ ì‹ ëª…'] == predicted_food_name]\n",
        "    if not nutrition_info.empty:\n",
        "        info = nutrition_info.iloc[0]\n",
        "        result_text = (\n",
        "            f\"**ë¶„ì„ ê²°ê³¼: {info['ìŒ ì‹ ëª…']}**\\n\"\n",
        "            f\"--- (100g ê¸°ì¤€ ì˜ì–‘ ì •ë³´) ---\\n\"\n",
        "            f\"ì¹¼ë¡œë¦¬: {info['ì—ë„ˆì§€(kcal)']} kcal\\n\"\n",
        "            f\"ë‹¨ë°±ì§ˆ: {info['ë‹¨ë°±ì§ˆ(g)']} g\\n\"\n",
        "            f\"ì§€ë°©: {info['ì§€ë°©(g)']} g\\n\"\n",
        "            f\"íƒ„ìˆ˜í™”ë¬¼: {info['íƒ„ìˆ˜í™”ë¬¼(g)']} g\\n\"\n",
        "        )\n",
        "        return result_text\n",
        "    else:\n",
        "        return f\"'{predicted_food_name}'ì— ëŒ€í•œ ì˜ì–‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\""
      ],
      "metadata": {
        "id": "dws9Ox_N-gwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nutrition_db.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0iNovtZGFkh",
        "outputId": "42ba6d70-178e-4e67-d56a-13f87cbe7277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ìŒ ì‹ ëª…', 'ì¤‘ëŸ‰(g)', 'ì—ë„ˆì§€(kcal)', 'íƒ„ìˆ˜í™”ë¬¼(g)', 'ë‹¹ë¥˜(g)', 'ì§€ë°©(g)', 'ë‹¨ë°±ì§ˆ(g)',\n",
            "       'ì¹¼ìŠ˜(mg)', 'ì¸(mg)', 'ë‚˜íŠ¸ë¥¨(mg)', 'ì¹¼ë¥¨(mg)', 'ë§ˆê·¸ë„¤ìŠ˜(mg)', 'ì² (mg)', 'ì•„ì—°(mg)',\n",
            "       'ì½œë ˆìŠ¤í…Œë¡¤(mg)', 'íŠ¸ëœìŠ¤ì§€ë°©(g)'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('foodim4.keras')"
      ],
      "metadata": {
        "id": "jB9A6NTNQIl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"foodim7.keras\")"
      ],
      "metadata": {
        "id": "CDdJcyMQQL-C"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2nbxxbuUDGS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# history ê°ì²´ì—ì„œ ì •í™•ë„ì™€ ì†ì‹¤ ê°’ í™•ì¸\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "XtKAeBfYQqWj"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Accuracy:\", train_accuracy[-1])\n",
        "print(\"Validation Accuracy:\", val_accuracy[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hAAOoDfQsbX",
        "outputId": "f781bddc-acc4-4ab3-f029-9ed240391777"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9158512949943542\n",
            "Validation Accuracy: 0.6480000019073486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "trained_model = tf.keras.models.load_model('foodim7.keras')"
      ],
      "metadata": {
        "id": "kLXeIT9UQw_0"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "results = trained_model.predict(img_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M5TY_JOUAgZ",
        "outputId": "a8b9c61f-351b-4189-83b7-00334022d714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x787c1d64df80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"food_labels ê¸¸ì´:\", len(food_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcPaUCjtUEkT",
        "outputId": "fbb4161c-c56e-4d7b-c936-b587ce53221a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "food_labels ê¸¸ì´: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PRhCdDbUHgE",
        "outputId": "095304d1-824f-4d6e-d188-00184902dbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/foodImage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the predict function should work correctly.\n",
        "results = trained_model.predict(img_array)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ZYRFHfUOe8",
        "outputId": "a1cda42b-a510-48f4-aa2a-bd231bb1fb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "[[2.2989003e-07 1.6631458e-09 7.6916912e-08 1.9559285e-11 3.2113963e-03\n",
            "  9.9678826e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xW825X8_UscY"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. í•™ìŠµëœ ëª¨ë¸ê³¼ ì˜ì–‘ DB ë‹¤ì‹œ ë¡œë“œ\n",
        "loaded_model = load_model('/content/foodim9.keras')\n",
        "nutrition_db = pd.read_csv('/content/food.csv', encoding='UTF-8')"
      ],
      "metadata": {
        "id": "BsKix2oTUuxm"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. í´ë˜ìŠ¤ ì¸ë±ìŠ¤-ì´ë¦„ ë§¤í•‘\n",
        "class_indices = train_generator.class_indices\n",
        "class_names = {v: k for k, v in class_indices.items()}"
      ],
      "metadata": {
        "id": "IZ7sEhR8U300"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_analyze_nutrition(img_path):\n",
        "    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # ìŒì‹ ì˜ˆì¸¡\n",
        "    predictions = loaded_model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    predicted_food_name = class_names[predicted_class_index]\n",
        "\n",
        "    # ì˜ì–‘ ì •ë³´ ì°¾ê¸°\n",
        "    nutrition_info = nutrition_db[nutrition_db['ìŒ ì‹ ëª…'] == predicted_food_name]\n",
        "\n",
        "    if not nutrition_info.empty:\n",
        "        info = nutrition_info.iloc[0]\n",
        "        result_text = (\n",
        "            f\"**ë¶„ì„ ê²°ê³¼: {info['ìŒ ì‹ ëª…']}**\\n\"\n",
        "            f\"--- (100g ê¸°ì¤€ ì˜ì–‘ ì •ë³´) ---\\n\"\n",
        "            f\"ì¹¼ë¡œë¦¬: {info['ì—ë„ˆì§€(kcal)']} kcal\\n\"\n",
        "            f\"ë‹¨ë°±ì§ˆ: {info['ë‹¨ë°±ì§ˆ(g)']} g\\n\"\n",
        "            f\"ì§€ë°©: {info['ì§€ë°©(g)']} g\\n\"\n",
        "            f\"íƒ„ìˆ˜í™”ë¬¼: {info['íƒ„ìˆ˜í™”ë¬¼(g)']} g\\n\"\n",
        "        )\n",
        "        return result_text\n",
        "    else:\n",
        "        return f\"'{predicted_food_name}'ì— ëŒ€í•œ ì˜ì–‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\""
      ],
      "metadata": {
        "id": "0hOVLudMU63U"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Gradio ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸°\n",
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_and_analyze_nutrition,\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"ìŒì‹ ì´ë¯¸ì§€ ì—…ë¡œë“œ\"),\n",
        "    outputs=gr.Textbox(label=\"ì˜ì–‘ ë¶„ì„ ê²°ê³¼\"),\n",
        "    title=\"ìŒì‹ ì˜ì–‘ ë¶„ì„ê¸° ğŸ¥—\",\n",
        "    description=\"ìŒì‹ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì˜ì–‘ì†Œ ì •ë³´ë¥¼ ì˜ˆì¸¡í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "v2EpRgAxU9qL",
        "outputId": "b6819a74-820a-4edb-b4b3-29f097314452"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://65c527ef29c65a5ef5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://65c527ef29c65a5ef5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    }
  ]
}